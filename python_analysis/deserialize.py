import struct
from dataclasses import dataclass

# This is the same struct as defined in our C++ simulation, the order should also be the same
@dataclass
class Datapoint:
    t: float
    speed_x: float
    speed_y: float
    loc_x: float
    loc_y: float
    F_l: float

FIELD_COUNT = 6 # How many fields our datapoint struct has, this is used later
T_EXPORTFLOAT_SIZE = 8 # The size in bytes of the C++ t_exportfloat, a double is 8 bytes. The C++ program logs this size at startup
POINT_SIZE = FIELD_COUNT * T_EXPORTFLOAT_SIZE # Calculate the size in bytes of a single datapoint

def gen_fmt_string():
    str = "="
    for _ in range(FIELD_COUNT):
        str += "d"
    return str

FORMAT_STR = gen_fmt_string()
def read_point(idx, buffer):
    offset = idx * POINT_SIZE

    # Tell Python to parse the raw bytes from specified buffer at specified index as FIELD_COUNT doubles.
    # The gen_fmt_string generates a qualifier that tells Python to look for FIELD_COUNT doubles
    values = struct.unpack_from(FORMAT_STR, buffer, offset)
    return Datapoint(*values)

# The export file generated by the C++ program can get quite large, we define a buffer here that can hold 2 to the power of 20 datapoints.
# We use this buffer so that we do not have to read the entire file into RAM at once, as that might not even fit.
BUFFER_COUNT = 2 << 20
BUFFER_SIZE = BUFFER_COUNT * POINT_SIZE
class ExportReader:
    def __init__(self, path):
        # Open the export file
        self.file = open(path, "rb")
        self.buffer = None
        self.buffer_len = 0
        self.buffer_idx = 0
        self.fill_buffer()

    def destroy(self):
        # Close the export file
        self.file.close()
        self.file = None

    def fill_buffer(self):
        if not self.file.readable():
            # If we reached the end of the export file, do nothing
            self.buffer = None
            self.buffer_len = 0
            self.buffer_idx = 0
            return
        else:
            # Read as many bytes as possible from the file, but no more than can fit in our buffer
            self.buffer = self.file.read(BUFFER_SIZE)
            buffer_len = len(self.buffer)
            if buffer_len == 0:
                # We reached the end of the export file, do nothing
                self.buffer = None
                self.buffer_len = 0
                self.buffer_idx = 0
            else:
                # We may have read less points than our entire buffer can fit (eg. this is the last batch and wasn't filled completely by the C++ simulation)
                # Store how many datapoints we actually read from disk, to prevent errors later on
                self.buffer_len = len(self.buffer) / POINT_SIZE
        self.buffer_idx = 0

    def read_point(self):
        if self.buffer is None:
            # return None if the buffer is None (eg. our previous code set the buffer to None because it detected that we reached the end of the export file)
            return None
        point = read_point(self.buffer_idx, self.buffer)

        self.buffer_idx += 1
        if self.buffer_idx >= self.buffer_len:
            # If we reached the end of the buffer, try to fill the buffer again by reading more data from disk
            self.fill_buffer()

        return point
